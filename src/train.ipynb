{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import create_dir, replace_dir, Clock, compare_dir, split_parameters\n",
    "from transform_img import flatten_onehot, Diff_size_collect, get_transform, norm_black_color,get_pretreat_transform\n",
    "from loss import Soft_dice_loss, Focal_loss, SSIM, activate\n",
    "from plot import plot_grad_flow, Progress_writer, onehot_gird, Loss_record, Acc_record, Loss_writer,Acc_writer\n",
    "from dataset.dataset import Image_Dataset, Zip_dataset, get_data_files\n",
    "from dataset.tarpath import Tar_path\n",
    "from dataset.lmdb_format import Lmdb_dataset\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchsummary import summary\n",
    "\n",
    "from net.unet import U_Net\n",
    "from net.nested_unet import NestedUNet\n",
    "from net.regseg import RegSeg\n",
    "from net.regseg_p import RegSeg_dp\n",
    "\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "import copy\n",
    "from datetime import datetime, timedelta\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from torch.cuda.amp import GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查cuda\n",
    "TRAIN_ON_GPU = torch.cuda.is_available()\n",
    "\n",
    "if not TRAIN_ON_GPU:\n",
    "    print('CUDA is not available. Training on CPU')\n",
    "else:\n",
    "    print('CUDA is available. Training on GPU')\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if TRAIN_ON_GPU else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "# 模型参数\n",
    "LABEL_C1 = {\n",
    "    1: \"Human\"\n",
    "}\n",
    "LABEL_C5 = {\n",
    "    1: \"Hair\",\n",
    "    2: \"Face\",\n",
    "    3: \"body\",\n",
    "    4: \"Leg\",\n",
    "    5: \"Arm\"\n",
    "}\n",
    "LABEL_C12 = {\n",
    "    1: \"Hat\",\n",
    "    2: \"Hair\",\n",
    "    3: \"Arm\",\n",
    "    4: \"Sunglasses\",\n",
    "    5: \"Clothes\",\n",
    "    6: \"Dress\",\n",
    "    7: \"Leg\",\n",
    "    8: \"Pants\",\n",
    "    9: \"Torso-skin\",\n",
    "    10: \"Scarf\",\n",
    "    11: \"Skirt\",\n",
    "    12: \"Face\",\n",
    "}\n",
    "C12_TO_C5 = {\n",
    "    1: [1, 2],\n",
    "    2: [4, 12],\n",
    "    3: [5, 6, 9, 10],\n",
    "    4: [7, 8, 11],\n",
    "    5: [3,],\n",
    "}\n",
    "\n",
    "LABEL = LABEL_C5\n",
    "\n",
    "INPUT_CHANNEL = 3\n",
    "OUTPUT_CHANNEL = len(LABEL)+1 if len(LABEL) > 1 else 1\n",
    "\n",
    "DOWNSAMP_MULTI = 4\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "GRAD_ACCUMULATE = 1\n",
    "\n",
    "EPOCH = 50\n",
    "# 输入图片的大小\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "RANDOM_SEED = torch.default_generator.initial_seed()\n",
    "\n",
    "# 数据集参数\n",
    "SHUFFLE = True\n",
    "PIN_MEMORY = TRAIN_ON_GPU\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "EPOCH_SAVE = 5\n",
    "\n",
    "TEST_SIZE = 10\n",
    "# 数据目录\n",
    "DATA_DIR = \"../data/graduate/lip_c5_db\"\n",
    "\n",
    "TRAIN_IMG_DIR = \"./training\"\n",
    "TRAIN_GD_TRUTH_DIR = \"./training_seg\"\n",
    "\n",
    "VAL_IMG_DIR = \"./validation\"\n",
    "VAL_GD_TRUTH_DIR = \"./validation_seg\"\n",
    "\n",
    "TEST_IMG_DIR = \"./test\"\n",
    "\n",
    "# 创建数据的子集,如果小于1,创建对应比例的子集,大于1,创建对应数量的子集\n",
    "TRAIN_SUBSET = 1\n",
    "VALID_SUBSET = 1\n",
    "# 保存数据目录\n",
    "SAVE_DIR = Path('../model')\n",
    "\n",
    "# 是否比较训练图片和分割图片目录中的文件完全匹配\n",
    "COMPARE_FILE_NAME = False\n",
    "\n",
    "# 是否清除tensorboard的数据目录\n",
    "CLEAR_TENSOR_BOARD_RUNS = True\n",
    "# 如果不为None，作为模型参数加载\n",
    "STATE_DICT_PATH = \"../model/complete/RegSeg_align_3to6_e200_b8_s512/model/model_e199.pth\"\n",
    "SAVE_SUB_DIR = None\n",
    "# 重新开始的下一个epoch,epoch从0开始计数\n",
    "START_EPOCH = 0\n",
    "\n",
    "AMP = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model: torch.nn.Module, step_per_epoch: int, epoch: int):\n",
    "    initial_lr = 1e-4\n",
    "    lr = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    warm_up_step = 3000\n",
    "    start_lr_factor = 1e-5\n",
    "\n",
    "    max_step = epoch * step_per_epoch - warm_up_step\n",
    "    last_step = START_EPOCH * step_per_epoch - 1\n",
    "\n",
    "    verbose = False\n",
    "\n",
    "    para_decay, para_no_decay = split_parameters(model)\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {\"params\": para_decay, \"weight_decay\": weight_decay, \"initial_lr\": initial_lr},\n",
    "        {\"params\": para_no_decay, \"initial_lr\": initial_lr}\n",
    "    ], lr=lr)\n",
    "\n",
    "    warm_up_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_lr_factor, total_iters=warm_up_step, last_epoch=last_step, verbose=verbose)\n",
    "\n",
    "    # lam_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    #     optimizer,\n",
    "    #     lambda epoch: (1 - epoch/max_step)**0.9,\n",
    "    #     last_epoch=last_step, verbose=verbose)\n",
    "\n",
    "    cos_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, max_step, eta_min=1e-5, last_epoch=last_step, verbose=verbose)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "        optimizer,[warm_up_scheduler, cos_scheduler], [warm_up_step])\n",
    "\n",
    "    return optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "model = RegSeg_dp(INPUT_CHANNEL, OUTPUT_CHANNEL, 0)\n",
    "if STATE_DICT_PATH != None:\n",
    "    model.load_state_dict(torch.load(STATE_DICT_PATH))\n",
    "# else:\n",
    "#     state_dict: dict[str,] = torch.load(\n",
    "#         \"../model/RegSeg_dp_3to13_e50_b8_s512_dv3/model/model_e45.pth\")\n",
    "#     model.stem.load_state_dict(\n",
    "#         {k: v for k, v in state_dict.items() if k.startswith(\"stem\")}, strict=False)\n",
    "#     model.body.load_state_dict(\n",
    "#         {k: v for k, v in state_dict.items() if k.startswith(\"body\")}, strict=False)\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "summary(model, input_size=(3, 512, 512), batch_size=-1, device=DEVICE.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建需要路径\n",
    "create_dir(SAVE_DIR)\n",
    "\n",
    "save_sub_dir = SAVE_DIR / \"{}_{}to{}_e{}_b{}_s{}\".format(\n",
    "    model.__class__.__name__,\n",
    "    INPUT_CHANNEL, OUTPUT_CHANNEL,\n",
    "    EPOCH, BATCH_SIZE, IMAGE_SIZE)\n",
    "\n",
    "if SAVE_SUB_DIR == None:\n",
    "    replace_dir(save_sub_dir)\n",
    "\n",
    "    state_dir = save_sub_dir / \"state\"\n",
    "    model_dir = save_sub_dir / \"model\"\n",
    "    tensorboard_runs_dir = save_sub_dir / \"runs\"\n",
    "    \n",
    "    replace_dir(state_dir)\n",
    "    replace_dir(model_dir)\n",
    "    if CLEAR_TENSOR_BOARD_RUNS:\n",
    "        replace_dir(tensorboard_runs_dir)\n",
    "else:\n",
    "    save_sub_dir = Path(SAVE_SUB_DIR)\n",
    "\n",
    "    state_dir = save_sub_dir / \"state\"\n",
    "    model_dir = save_sub_dir / \"model\"\n",
    "    tensorboard_runs_dir = save_sub_dir / \"runs\"\n",
    "\n",
    "    create_dir(save_sub_dir)\n",
    "    create_dir(state_dir)\n",
    "    create_dir(model_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建writer\n",
    "writer = SummaryWriter(log_dir=str(tensorboard_runs_dir))\n",
    "writer.add_text(\"Basic/Model\",\n",
    "                \"\"\"batch size: {}\n",
    "epoch: {}\n",
    "image size: {}\n",
    "random seed: {}\n",
    "\"\"\".format(BATCH_SIZE, EPOCH, IMAGE_SIZE, RANDOM_SEED)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看模型结构\n",
    "def write_graph():\n",
    "    writer.add_graph(model, torch.rand(\n",
    "            (BATCH_SIZE, INPUT_CHANNEL, IMAGE_SIZE, IMAGE_SIZE), device=DEVICE),use_strict_trace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集\n",
    "# 对比目录中的数据是否匹配\n",
    "if COMPARE_FILE_NAME:\n",
    "    if tarfile.is_tarfile(DATA_DIR):\n",
    "        data_path = Tar_path.make_tar_root_path(DATA_DIR)\n",
    "    else:\n",
    "        data_path = Path(DATA_DIR)\n",
    "\n",
    "    if not compare_dir(data_path/TRAIN_IMG_DIR, data_path/TRAIN_GD_TRUTH_DIR):\n",
    "        raise RuntimeError(\"Data dir {} and {} dose not match.\")\n",
    "\n",
    "    if not compare_dir(data_path/VAL_IMG_DIR, data_path/VAL_GD_TRUTH_DIR):\n",
    "        raise RuntimeError(\"Data dir {} and {} dose not match.\")\n",
    "    del data_path\n",
    "\n",
    "# #############################\n",
    "# transform, target_transform, transform_rm_rand_layer, target_transform_rm_rand_layer = get_transform(IMAGE_SIZE,\n",
    "#                                                                                                      OUTPUT_CHANNEL)\n",
    "\n",
    "# # 创建训练数据集\n",
    "# train_img_dataset = Image_Dataset(\n",
    "#     get_data_files(TRAIN_IMG_DIR, DATA_DIR), transform)\n",
    "\n",
    "# train_target_img_dataset = Image_Dataset(\n",
    "#     get_data_files(TRAIN_GD_TRUTH_DIR, DATA_DIR), target_transform, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# train_dataset = Zip_dataset(train_img_dataset, train_target_img_dataset)\n",
    "# # 验证数据集\n",
    "# val_img_dataset = Image_Dataset(\n",
    "#     get_data_files(VAL_IMG_DIR, DATA_DIR), transform_rm_rand_layer)\n",
    "\n",
    "# val_target_img_dataset = Image_Dataset(\n",
    "#     get_data_files(VAL_GD_TRUTH_DIR, DATA_DIR), target_transform_rm_rand_layer, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# val_dataset = Zip_dataset(val_img_dataset, val_target_img_dataset)\n",
    "\n",
    "# # 测试数据集\n",
    "# test_transform = transform_rm_rand_layer.transforms\n",
    "# test_transform = torchvision.transforms.Compose(test_transform)\n",
    "\n",
    "\n",
    "# class Test_Img_dataset(Image_Dataset):\n",
    "\n",
    "#     def __getitem__(self: Image_Dataset, idx: int):\n",
    "#         path = self.get_image_path(idx)\n",
    "#         transform_img, img = self.read_image(path)\n",
    "#         return transform_img, img\n",
    "\n",
    "\n",
    "# test_dataset = Test_Img_dataset(get_data_files(\n",
    "#     TEST_IMG_DIR, DATA_DIR), test_transform)\n",
    "\n",
    "# Lmdb######################################\n",
    "transform, target_transform, transform_rm_rand_layer, target_transform_rm_rand_layer = get_pretreat_transform(\n",
    "    OUTPUT_CHANNEL)\n",
    "\n",
    "# 创建训练数据集\n",
    "train_img_dataset = Lmdb_dataset(DATA_DIR, TRAIN_IMG_DIR, transform)\n",
    "\n",
    "train_target_img_dataset = Lmdb_dataset(\n",
    "    DATA_DIR, TRAIN_GD_TRUTH_DIR, target_transform)\n",
    "\n",
    "train_dataset = Zip_dataset(train_img_dataset, train_target_img_dataset)\n",
    "# 验证数据集\n",
    "val_img_dataset = Lmdb_dataset(\n",
    "    DATA_DIR, VAL_IMG_DIR, transform_rm_rand_layer)\n",
    "\n",
    "val_target_img_dataset = Lmdb_dataset(\n",
    "    DATA_DIR, VAL_GD_TRUTH_DIR, target_transform_rm_rand_layer)\n",
    "\n",
    "val_dataset = Zip_dataset(val_img_dataset, val_target_img_dataset)\n",
    "\n",
    "# 测试数据集\n",
    "test_transform = [torchvision.transforms.Lambda(\n",
    "    lambda img:cv2.cvtColor(img, cv2.COLOR_BGR2RGB))] + transform_rm_rand_layer.transforms\n",
    "test_transform = torchvision.transforms.Compose(test_transform)\n",
    "\n",
    "\n",
    "class Test_lmdb_dataset(Lmdb_dataset):\n",
    "\n",
    "    def __getitem__(self: Image_Dataset, idx: int):\n",
    "        path = self.get_image_path(idx)\n",
    "        transform_img, img = self.read_image(path)\n",
    "        return transform_img, img\n",
    "\n",
    "\n",
    "test_dataset = Test_lmdb_dataset(DATA_DIR, TEST_IMG_DIR, test_transform)\n",
    "\n",
    "# 使用一部分数据测试代码\n",
    "if TRAIN_SUBSET < 1.:\n",
    "    train_dataset = Subset(train_dataset,\n",
    "                           list(range(int(len(train_dataset)*TRAIN_SUBSET))))\n",
    "elif TRAIN_SUBSET > 1.:\n",
    "    train_dataset = Subset(train_dataset,\n",
    "                           list(range(int(TRAIN_SUBSET))))\n",
    "if VALID_SUBSET < 1.:\n",
    "    val_dataset = Subset(val_dataset,\n",
    "                         list(range(int(len(val_dataset)*VALID_SUBSET))))\n",
    "elif VALID_SUBSET > 1.:\n",
    "    val_dataset = Subset(val_dataset,\n",
    "                         list(range(int(VALID_SUBSET))))\n",
    "\n",
    "# 测试dataset\n",
    "for x, y in islice(train_dataset, 1):\n",
    "    print(torch.bincount(y.int().flatten()))\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.imshow(x.permute((1, 2, 0)))\n",
    "    plt.subplot(212)\n",
    "    plt.imshow(onehot_gird(y).permute((1, 2, 0)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据批处理\n",
    "\n",
    "gd_black = torch.zeros((OUTPUT_CHANNEL, 1, 1))\n",
    "if OUTPUT_CHANNEL > 1:\n",
    "    gd_black[0, ...] = torch.tensor([1])\n",
    "\n",
    "data_loader_para = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": SHUFFLE,\n",
    "    \"pin_memory\": PIN_MEMORY,\n",
    "    \"num_workers\": NUM_WORKERS,\n",
    "    \"collate_fn\": lambda imgs: Diff_size_collect.collect_fn(\n",
    "        imgs, DOWNSAMP_MULTI,\n",
    "        black={\n",
    "            0: torch.tensor(norm_black_color).reshape((3, 1, 1)),\n",
    "            1: gd_black\n",
    "        }),\n",
    "}\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset, **copy.copy(data_loader_para)\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    val_dataset, **copy.copy(data_loader_para)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_img(inputs: torch.Tensor, predictions: tuple[torch.Tensor]):\n",
    "    # 将所有图像上采样到统一大小\n",
    "    size = inputs.shape[2:4]\n",
    "    predictions = [F.interpolate(i, size) for i in predictions]\n",
    "\n",
    "    result: list[torch.Tensor] = []\n",
    "    for input, *preds in zip(inputs, *predictions):\n",
    "        # 前景分割图像\n",
    "        pred_label = flatten_onehot(preds[-1])\n",
    "        front_seg = input.clone()\n",
    "        front_seg[:, pred_label == 0] = torch.tensor(\n",
    "            norm_black_color).reshape((3, 1))\n",
    "\n",
    "        perform_imgs = torchvision.utils.make_grid(\n",
    "            [input, front_seg], normalize=True)\n",
    "        output_imgs = [perform_imgs] + [onehot_gird(p) for p in preds]\n",
    "\n",
    "        width = max(*[img.size(-1) for img in output_imgs])\n",
    "        coll_out_imgs = []\n",
    "        for img in output_imgs:\n",
    "            left_len = width - img.size(-1)\n",
    "            if left_len != 0:\n",
    "                complement = torch.zeros((3, 1, 1), dtype=img.dtype).expand(\n",
    "                    (3, img.size(1), left_len))\n",
    "                img = torch.cat([img, complement], -1)\n",
    "            coll_out_imgs.append(img.cpu())\n",
    "\n",
    "        result.append(torch.cat(coll_out_imgs, 1))\n",
    "    return result\n",
    "\n",
    "\n",
    "def writer_output(output, index, epoch):\n",
    "    writer.add_image(\"Test/Prediction_{}\".format(index), output, epoch)\n",
    "\n",
    "\n",
    "def file_output(out_dir: Path, output: torch.Tensor, index, epoch):\n",
    "    if not isinstance(out_dir, Path):\n",
    "        out_dir = Path(out_dir)\n",
    "\n",
    "    out_file = out_dir/\"e{}i_{}.jpg\".format(epoch, index)\n",
    "    torchvision.utils.save_image(output, out_file)\n",
    "\n",
    "\n",
    "def test(model: torch.nn.Module, epoch: int, test_size=4, output_fn=writer_output):\n",
    "    \"\"\"使用测试数据测试模型\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # 获取图像\n",
    "        if test_size < 0:\n",
    "            rands = torch.arange(0, len(test_dataset))\n",
    "        else:\n",
    "            rands = torch.randint(0, len(test_dataset), (test_size,))\n",
    "\n",
    "        for i, r in enumerate(rands):\n",
    "            test_img, _ = test_dataset[r]\n",
    "\n",
    "            test_imgs, = Diff_size_collect.collect_fn(\n",
    "                [(test_img,)], DOWNSAMP_MULTI,\n",
    "                black={\n",
    "                    0: torch.tensor(norm_black_color).reshape((3, 1, 1))\n",
    "                })\n",
    "\n",
    "            # 预测\n",
    "            pred_test_imgs = model(test_imgs.to(DEVICE))\n",
    "            if not isinstance(pred_test_imgs, (tuple, list)):\n",
    "                pred_test_imgs = (pred_test_imgs,)\n",
    "\n",
    "            pred_test_imgs = [activate(i) for i in pred_test_imgs]\n",
    "\n",
    "            output, = plot_test_img(test_imgs, pred_test_imgs)\n",
    "            output_fn(output, i, epoch)\n",
    "\n",
    "\n",
    "def test_dataloader():\n",
    "    with torch.no_grad():\n",
    "        for x, y in islice(train_data_loader, 1):\n",
    "            test_outputs = plot_test_img(x, (y,))\n",
    "            for i, out in enumerate(test_outputs):\n",
    "                writer.add_image(\n",
    "                    \"Test TR DataLoader/target_{}\".format(i), out)\n",
    "                \n",
    "        for x, y in islice(valid_data_loader, 1):\n",
    "            test_outputs = plot_test_img(x, (y,))\n",
    "            for i, out in enumerate(test_outputs):\n",
    "                writer.add_image(\n",
    "                    \"Test VL DataLoader/target_{}\".format(i), out)\n",
    "\n",
    "\n",
    "test(model, START_EPOCH, TEST_SIZE)\n",
    "# test(model, 0, -1, lambda *args: file_output(\"../tmp/test2\", *args))\n",
    "\n",
    "test_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器\n",
    "optimizer, scheduler = get_optimizer(\n",
    "    model, len(train_data_loader), EPOCH)\n",
    "##################################\n",
    "# 损失函数\n",
    "\n",
    "\n",
    "class Binary_loss(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 focal: torch.nn.Module,\n",
    "                 ssim: torch.nn.Module,\n",
    "                 dice: torch.nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        self.focal_loss = focal\n",
    "        self.ssim_loss = ssim\n",
    "        self.dice_loss = dice\n",
    "\n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor):\n",
    "        loss = self.focal_loss(input, target)\n",
    "        input = torch.sigmoid(input)\n",
    "        loss += self.ssim_loss(input, target) + self.dice_loss(input, target)\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def mk_loss_record(focal_loss, ssim_loss, dice_loss, step: int):\n",
    "        focal_record = Loss_record(focal_loss, step)\n",
    "        ssim_record = Loss_record(ssim_loss, step)\n",
    "        dice_record = Loss_record(dice_loss, step)\n",
    "\n",
    "        loss = Binary_loss(focal_record, ssim_record, dice_record)\n",
    "        loss_record = Loss_record(loss, step)\n",
    "        return focal_record, ssim_record, dice_record, loss_record\n",
    "\n",
    "\n",
    "class Multi_class_loss(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 focal: torch.nn.Module,\n",
    "                 ssim: torch.nn.Module,\n",
    "                 dice: torch.nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        self.focal_loss = focal\n",
    "        self.ssim_loss = ssim\n",
    "        self.dice_loss = dice\n",
    "\n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor):\n",
    "        loss = self.focal_loss(input, target) if self.focal_loss != None else 0\n",
    "        input = torch.softmax(input, 1)\n",
    "        loss += self.ssim_loss(input, target) if self.ssim_loss != None else 0\n",
    "        loss += self.dice_loss(input, target) if self.dice_loss != None else 0\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def mk_loss_record(focal_loss, ssim_loss, dice_loss, step: int):\n",
    "        records: list[Loss_record] = []\n",
    "        for loss_fn in (focal_loss, ssim_loss, dice_loss):\n",
    "            if loss_fn != None:\n",
    "                records.append(Loss_record(loss_fn, step))\n",
    "            else:\n",
    "                records.append(None)\n",
    "\n",
    "        loss = Multi_class_loss(*records)\n",
    "        loss_record = Loss_record(loss, step)\n",
    "        return *[record for record in records if record != None], loss_record\n",
    "\n",
    "\n",
    "class Deep_sup_loss(torch.nn.Module):\n",
    "    def __init__(self, *layer_loss: torch.nn.Module, weights=None) -> None:\n",
    "        super().__init__()\n",
    "        self.layer_loss = layer_loss\n",
    "        self.weights = weights\n",
    "\n",
    "        if self.weights == None:\n",
    "            self.weights = torch.empty((len(self.layer_loss),)).fill_(1)\n",
    "\n",
    "    def forward(self, *input: torch.Tensor, target: torch.Tensor):\n",
    "        loss = []\n",
    "        for loss_fn, in_lay in zip(self.layer_loss, reversed(input)):\n",
    "            if in_lay.size() != target.size():\n",
    "                target = F.interpolate(\n",
    "                    target, in_lay.size()[-2:], mode=\"nearest-exact\")\n",
    "            loss.append(loss_fn(in_lay, target))\n",
    "\n",
    "        return (torch.stack(loss) * self.weights.to(target.device)).sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def mk_loss_record(focal_loss, ssim_loss, dice_loss, layer_weights: list[float], step: int):\n",
    "\n",
    "        records = []\n",
    "        layer_loss = []\n",
    "        for i in range(1, len(layer_weights)+1):\n",
    "            r = Multi_class_loss.mk_loss_record(\n",
    "                focal_loss, ssim_loss, dice_loss, step)\n",
    "            layer_loss.append(r[-1])\n",
    "            records.append(list(r))\n",
    "\n",
    "        deep_sup_loss = Deep_sup_loss(*layer_loss, weights=layer_weights)\n",
    "        deep_sup_record = Loss_record(deep_sup_loss, step)\n",
    "        records.append([deep_sup_record])\n",
    "        return records\n",
    "\n",
    "\n",
    "if OUTPUT_CHANNEL == 1:\n",
    "    focal_loss = Focal_loss(alpha=0.5, mul_class=False)\n",
    "    ssim_loss = SSIM(activated=True)\n",
    "    dice_loss = Soft_dice_loss(activated=True)\n",
    "\n",
    "    train_loss = Binary_loss.mk_loss_record(\n",
    "        focal_loss, ssim_loss, dice_loss, len(train_data_loader))\n",
    "    valid_loss = Binary_loss.mk_loss_record(\n",
    "        focal_loss, ssim_loss, dice_loss, len(valid_data_loader))\n",
    "else:\n",
    "    focal_loss = Focal_loss(1.)\n",
    "    # ssim_loss = SSIM(activated=True)\n",
    "    ssim_loss = None\n",
    "    dice_loss = Soft_dice_loss(activated=True)\n",
    "\n",
    "    train_loss = Multi_class_loss.mk_loss_record(\n",
    "        focal_loss, ssim_loss, dice_loss, len(train_data_loader))\n",
    "    valid_loss = Multi_class_loss.mk_loss_record(\n",
    "        focal_loss, ssim_loss, dice_loss, len(valid_data_loader))\n",
    "\n",
    "loss_writer = Loss_writer(\n",
    "    *[(l, \"Training\") for l in train_loss],\n",
    "    *[(l, \"Validation\") for l in valid_loss], writer=writer)\n",
    "\n",
    "train_loss: Loss_record = train_loss[-1]\n",
    "valid_loss: Loss_record = valid_loss[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 监控训练过程\n",
    "clock = Clock()\n",
    "print_timer = clock.set_timer(timedelta(seconds=30))\n",
    "\n",
    "\n",
    "def write_now_time():\n",
    "    writer.add_text(\"Basic/time\", str(datetime.now()))\n",
    "\n",
    "\n",
    "progress_writer = Progress_writer(writer, \"Basic/Progress\")\n",
    "\n",
    "acc_record = Acc_record(len(valid_data_loader.dataset), len(LABEL)+1)\n",
    "acc_writer = Acc_writer(writer, acc_record, LABEL)\n",
    "# 记录epoch数据\n",
    "valid_loss_min = np.Inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练步骤\n",
    "scaler = GradScaler()\n",
    "\n",
    "\n",
    "def train_step(batch_index: int, epoch: int, x: torch.Tensor, y: torch.Tensor):\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    # 训练步骤\n",
    "    optimize = (batch_index+1) % GRAD_ACCUMULATE == 0\n",
    "    if GRAD_ACCUMULATE == 1 or (batch_index+1) % GRAD_ACCUMULATE == 1:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if AMP:\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            prediction: tuple[torch.Tensor] = model(x)\n",
    "            if not isinstance(prediction, (tuple, list)):\n",
    "                prediction = (prediction,)\n",
    "            loss: torch.Tensor = train_loss(*prediction, target=y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if optimize:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "    else:\n",
    "        prediction: tuple[torch.Tensor] = model(x)\n",
    "        if not isinstance(prediction, (tuple, list)):\n",
    "            prediction = (prediction,)\n",
    "        loss: torch.Tensor = train_loss(*prediction, target=y)\n",
    "\n",
    "        loss.backward()\n",
    "        if optimize:\n",
    "            optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # 记录\n",
    "    for tensor_ in x, y, *prediction, loss:\n",
    "        tensor_.detach_()\n",
    "\n",
    "    total_step = epoch * len(train_data_loader) + batch_index\n",
    "\n",
    "    if clock.is_timeout(print_timer) or batch_index == len(train_data_loader)-1:\n",
    "        write_now_time()\n",
    "        # 统计每一层梯度\n",
    "        fig = plot_grad_flow(model.named_parameters())\n",
    "        writer.add_figure(\n",
    "            \"Training/Gradients\", fig, total_step)\n",
    "        # 统计loss分布变化\n",
    "        loss_writer.write_histogram(total_step, \"Training\")\n",
    "        # 记录进度\n",
    "        progress_writer.plot(batch_index+1, len(\n",
    "            train_data_loader), \"Training Batch\")\n",
    "\n",
    "        writer.add_scalar(\"Basic/learning rate\",\n",
    "                          scheduler.get_last_lr()[0], total_step)\n",
    "\n",
    "    if batch_index == len(train_data_loader)-1:\n",
    "        # 统计梯度和权重的分布\n",
    "        for name, param in model.named_parameters():\n",
    "            name = name.replace('.', '/')\n",
    "            writer.add_histogram(\n",
    "                \"Model weight/{}\".format(name),\n",
    "                param.data.detach().cpu(), epoch)\n",
    "            if param.grad != None:\n",
    "                writer.add_histogram(\n",
    "                    \"Model gradient/{}\".format(name),\n",
    "                    param.grad.data.detach().cpu(), epoch)\n",
    "\n",
    "\n",
    "def valid_step(batch_index: int, epoch: int, x: torch.Tensor, y: torch.Tensor):\n",
    "\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "    prediction: tuple[torch.Tensor] = model(x)\n",
    "    if not isinstance(prediction, (tuple, list)):\n",
    "        prediction = (prediction,)\n",
    "    loss: torch.Tensor = valid_loss(*prediction, target=y)\n",
    "\n",
    "    total_step = epoch * len(valid_data_loader) + batch_index\n",
    "\n",
    "    # 计算IOU\n",
    "    prediction = activate(prediction[-1])\n",
    "    \n",
    "    if prediction.size(1) > 1 and y.size(1) > 1:\n",
    "        prediction = torch.argmax(prediction, dim=1, keepdim=True)\n",
    "        y = torch.argmax(y, dim=1, keepdim=True)\n",
    "    elif prediction.size(1) > 1 and y.size(1) == 1:\n",
    "        prediction = torch.argmax(\n",
    "            prediction, dim=1, keepdim=True) > 0\n",
    "        prediction = prediction.to(torch.int32)\n",
    "        y = y.to(torch.int32)\n",
    "    elif prediction.size(1) == 1 and y.size(1) > 1:\n",
    "        prediction = prediction > 0.5\n",
    "        prediction = prediction.to(torch.int32)\n",
    "        \n",
    "        if y.size(1) != 1:\n",
    "            y = torch.argmax(y, dim=1, keepdim=True) > 0\n",
    "            y = y.to(torch.int32)\n",
    "\n",
    "\n",
    "    acc_record.calculate(prediction, y)\n",
    "\n",
    "    if clock.is_timeout(print_timer) or batch_index == len(valid_data_loader)-1:\n",
    "        write_now_time()\n",
    "        # 统计loss分布\n",
    "        loss_writer.write_histogram(total_step, \"Validation\")\n",
    "        # 统计每一类的iou分布\n",
    "        acc_writer.write_histogram(total_step)\n",
    "\n",
    "        # 记录进度\n",
    "        progress_writer.plot(batch_index+1, len(valid_data_loader),\n",
    "                             \"Validation Batch\")\n",
    "\n",
    "\n",
    "def record_epoch_data(current_epoch: int):\n",
    "\n",
    "    global valid_loss_min\n",
    "\n",
    "    # 记录loss变化\n",
    "    loss_writer.write_scalas(\"Loss\", current_epoch)\n",
    "    # 记录iou变化\n",
    "    acc_writer.write_scalas(current_epoch)\n",
    "    # 记录进度\n",
    "    progress_writer.plot(current_epoch+1, EPOCH, \"Epoch\")\n",
    "    # 保存模型\n",
    "    mean_valid_loss = valid_loss.log.mean()\n",
    "    if mean_valid_loss <= valid_loss_min and EPOCH_SAVE <= current_epoch:\n",
    "        writer.add_text(\"Basic/Saving model\",\n",
    "                        'Validation loss decreased ({:.6f} --> {:.6f}).  Saving model'.format(valid_loss_min, mean_valid_loss), current_epoch)\n",
    "\n",
    "        torch.save(model.state_dict(),\n",
    "                   str(model_dir / 'model_e{}.pth'.format(current_epoch)))\n",
    "\n",
    "        valid_loss_min = mean_valid_loss\n",
    "\n",
    "    writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "matplotlib.use(\"agg\")\n",
    "for epoch_index in range(START_EPOCH, EPOCH):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_index, (x, y) in enumerate(train_data_loader):\n",
    "        train_step(batch_index, epoch_index, x, y)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (x, y) in enumerate(valid_data_loader):\n",
    "            valid_step(batch_index, epoch_index, x, y)\n",
    "\n",
    "        test(model, epoch_index, TEST_SIZE)\n",
    "        record_epoch_data(epoch_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试性能\n",
    "def test_perf():\n",
    "    wait = 5\n",
    "    warmup = 5\n",
    "    active = 10\n",
    "    repeat = 2\n",
    "    with torch.profiler.profile(\n",
    "            schedule=torch.profiler.schedule(\n",
    "                wait=wait, warmup=warmup, active=active, repeat=repeat),\n",
    "            on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
    "                \"./runs/performance\"),\n",
    "            record_shapes=True,\n",
    "            profile_memory=True,\n",
    "            with_stack=True\n",
    "    ) as prof:\n",
    "        model.train()\n",
    "\n",
    "        for batch_index, (x, y) in enumerate(train_data_loader):\n",
    "            if batch_index >= (wait+warmup+active) * repeat:\n",
    "                break\n",
    "            train_step(batch_index, 0, x, y)\n",
    "            prof.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
